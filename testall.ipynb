{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2383e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, r2_score\n",
    "import joblib\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99cb1798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target lÃ  dáº¡ng sá»‘ (regression).\n",
      "========================================\n",
      "ðŸ”¹ RandomForest\n",
      "RMSE: 2.6685331127821983\n",
      "R2 Score: 0.980784255312577\n",
      "========================================\n",
      "ðŸ”¹ SVM\n",
      "RMSE: 2.3207751929970395\n",
      "R2 Score: 0.9854662336292253\n",
      "========================================\n",
      "ðŸ”¹ LinearRegression\n",
      "RMSE: 2.020551508505045\n",
      "R2 Score: 0.9889832909573141\n",
      "========================================\n",
      "ðŸ”¹ KNN\n",
      "RMSE: 2.913866846648968\n",
      "R2 Score: 0.9770886103261632\n",
      "========================================\n",
      "ðŸ”¹ DecisionTree\n",
      "RMSE: 2.528574526666764\n",
      "R2 Score: 0.9827470428226587\n",
      "========================================\n",
      "ðŸ”¹ MLP\n",
      "RMSE: 2.030836644763437\n",
      "R2 Score: 0.9888708496384566\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# 1. Import Libraries\n",
    "# ==========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report,\n",
    "    mean_squared_error, r2_score\n",
    ")\n",
    "\n",
    "# ==========================\n",
    "# 2. Load Dataset\n",
    "# ==========================\n",
    "data = pd.read_csv(\"Student_Performance.csv\")  # Ä‘á»•i file táº¡i Ä‘Ã¢y\n",
    "\n",
    "# Drop NaN chá»‰ trong target\n",
    "data = data.dropna(subset=[data.columns[-1]])\n",
    "target_col = data.columns[-1]\n",
    "X = data.drop(columns=[target_col])\n",
    "y = data[target_col]\n",
    "\n",
    "# Convert target náº¿u lÃ  sá»‘ nhÆ°ng bá»‹ lÆ°u dáº¡ng object\n",
    "if y.dtype == 'object':\n",
    "    try:\n",
    "        y = pd.to_numeric(y, errors='ignore')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ==========================\n",
    "# 3. Preprocessing\n",
    "# ==========================\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler(with_mean=False))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=True, max_categories=50))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    sparse_threshold=0.3\n",
    ")\n",
    "\n",
    "# ==========================\n",
    "# 4. Train Model Functions\n",
    "# ==========================\n",
    "\n",
    "# --- Classification Models ---\n",
    "def train_random_forest_classifier(X_train, y_train, preprocessor):\n",
    "    return Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(\n",
    "            n_estimators=50, max_depth=10, \n",
    "            max_features=\"sqrt\", random_state=42, n_jobs=-1))\n",
    "    ]).fit(X_train, y_train)\n",
    "\n",
    "def train_svm_classifier(X_train, y_train, preprocessor):\n",
    "    return Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', SVC())\n",
    "    ]).fit(X_train, y_train)\n",
    "\n",
    "def train_logistic_regression(X_train, y_train, preprocessor):\n",
    "    return Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LogisticRegression(max_iter=500))\n",
    "    ]).fit(X_train, y_train)\n",
    "\n",
    "def train_knn_classifier(X_train, y_train, preprocessor, n_neighbors=5):\n",
    "    return Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', KNeighborsClassifier(n_neighbors=n_neighbors))\n",
    "    ]).fit(X_train, y_train)\n",
    "\n",
    "def train_decision_tree_classifier(X_train, y_train, preprocessor):\n",
    "    return Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', DecisionTreeClassifier(max_depth=10, random_state=42))\n",
    "    ]).fit(X_train, y_train)\n",
    "\n",
    "def train_naive_bayes_classifier(X_train, y_train, preprocessor):\n",
    "    return Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', GaussianNB())\n",
    "    ]).fit(X_train, y_train)\n",
    "\n",
    "def train_mlp_classifier(X_train, y_train, preprocessor):\n",
    "    return Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42))\n",
    "    ]).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# --- Regression Models ---\n",
    "def train_random_forest_regressor(X_train, y_train, preprocessor):\n",
    "    return Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', RandomForestRegressor(\n",
    "            n_estimators=50, max_depth=10,\n",
    "            max_features=\"sqrt\", random_state=42, n_jobs=-1))\n",
    "    ]).fit(X_train, y_train)\n",
    "\n",
    "def train_svm_regressor(X_train, y_train, preprocessor):\n",
    "    return Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', SVR())\n",
    "    ]).fit(X_train, y_train)\n",
    "\n",
    "def train_linear_regression(X_train, y_train, preprocessor):\n",
    "    return Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', LinearRegression())\n",
    "    ]).fit(X_train, y_train)\n",
    "\n",
    "def train_knn_regressor(X_train, y_train, preprocessor, n_neighbors=5):\n",
    "    return Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', KNeighborsRegressor(n_neighbors=n_neighbors))\n",
    "    ]).fit(X_train, y_train)\n",
    "\n",
    "def train_decision_tree_regressor(X_train, y_train, preprocessor):\n",
    "    return Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', DecisionTreeRegressor(max_depth=10, random_state=42))\n",
    "    ]).fit(X_train, y_train)\n",
    "\n",
    "def train_mlp_regressor(X_train, y_train, preprocessor):\n",
    "    return Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', MLPRegressor(hidden_layer_sizes=(100,), max_iter=300, random_state=42))\n",
    "    ]).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 5. Evaluate Functions\n",
    "# ==========================\n",
    "def evaluate_classification(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "def evaluate_regression(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    print(\"R2 Score:\", r2_score(y_test, y_pred))\n",
    "\n",
    "# ==========================\n",
    "# 6. Evaluate All Models\n",
    "# ==========================\n",
    "def evaluate_all_models(X_train, y_train, X_test, y_test, preprocessor, task=\"classification\"):\n",
    "    models = {}\n",
    "    if task == \"classification\":\n",
    "        models = {\n",
    "            \"RandomForest\": train_random_forest_classifier,\n",
    "            \"SVM\": train_svm_classifier,\n",
    "            \"LogisticRegression\": train_logistic_regression,\n",
    "            \"KNN\": train_knn_classifier,\n",
    "            \"DecisionTree\": train_decision_tree_classifier,\n",
    "            \"NaiveBayes\": train_naive_bayes_classifier,\n",
    "            \"MLP\": train_mlp_classifier\n",
    "        }\n",
    "    else:\n",
    "        models = {\n",
    "            \"RandomForest\": train_random_forest_regressor,\n",
    "            \"SVM\": train_svm_regressor,\n",
    "            \"LinearRegression\": train_linear_regression,\n",
    "            \"KNN\": train_knn_regressor,\n",
    "            \"DecisionTree\": train_decision_tree_regressor,\n",
    "            \"MLP\": train_mlp_regressor\n",
    "        }\n",
    "\n",
    "    for name, trainer in models.items():\n",
    "        print(\"=\"*40)\n",
    "        print(f\"ðŸ”¹ {name}\")\n",
    "        try:\n",
    "            model = trainer(X_train, y_train, preprocessor)\n",
    "            if task == \"classification\":\n",
    "                evaluate_classification(model, X_test, y_test)\n",
    "            else:\n",
    "                evaluate_regression(model, X_test, y_test)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in {name}: {e}\")\n",
    "\n",
    "# ==========================\n",
    "# 7. Main Logic\n",
    "# ==========================\n",
    "if y.dtype == 'object':  \n",
    "    print(\"Target lÃ  dáº¡ng phÃ¢n loáº¡i (classification).\")\n",
    "    evaluate_all_models(X_train, y_train, X_test, y_test, preprocessor, task=\"classification\")\n",
    "else:\n",
    "    print(\"Target lÃ  dáº¡ng sá»‘ (regression).\")\n",
    "    evaluate_all_models(X_train, y_train, X_test, y_test, preprocessor, task=\"regression\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38bd0fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.913866846648968\n",
      "R2 Score: 0.9770886103261632\n"
     ]
    }
   ],
   "source": [
    "clf = train_knn_regressor(X_train, y_train, preprocessor)\n",
    "evaluate_regression(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434f6e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ThÃ´ng tin sinh viÃªn / nhÃ³m\n",
    "Lop   = \"ML2025\"\n",
    "Nhom  = \"11\"\n",
    "MSSV  = \"23714291\"\n",
    "HoTen = \"Nguyen Van A\"\n",
    "SoMay = \"01\"\n",
    "\n",
    "metadata = {\n",
    "    \"Lop\": Lop,\n",
    "    \"Nhom\": Nhom,\n",
    "    \"MSSV\": MSSV,\n",
    "    \"HoTen\": HoTen,\n",
    "    \"SoMay\": SoMay,\n",
    "    \"TaoLuc\": datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "}\n",
    "\n",
    "save_obj = {\n",
    "    \"model\": model,\n",
    "    \"metadata\": metadata\n",
    "}\n",
    "\n",
    "joblib.dump(save_obj, \"model.pkl\")\n",
    "print(\" Model and metadata saved to model.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
